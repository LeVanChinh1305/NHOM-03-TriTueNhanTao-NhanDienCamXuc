import cv2 # th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh, ƒë·ªçc camera v√† hi·ªÉn th·ªã c·ª≠a s·ªï
import mediapipe as mp # th∆∞ vi·ªán x·ª≠ l√Ω nh·∫≠n di·ªán khu√¥n m·∫∑t
import os # th∆∞ vi·ªán thao t√°c v·ªõi h·ªá th·ªëng file
import time # th∆∞ vi·ªán x·ª≠ l√Ω th·ªùi gian (tr·ªÖ)

# =========================
# DANH S√ÅCH C·∫¢M X√öC THEO TH·ª® T·ª∞
# =========================
EMOTIONS = ["batngo", "binhThuong", "buon", "tucgian", "vuive"]

# =========================
# TH∆Ø M·ª§C CH·ª®A D·ªÆ LI·ªÜU
# =========================
DATA_DIR = "Data"# t√™n th∆∞ m·ª•c g·ªëc ch·ª©a d·ªØ li·ªáu c·∫£m x√∫c

# =========================
# CAMERA INDEX
# =========================
CAMERA_INDEX = 0     # Camera c·ªßa b·∫°n

# =========================
# MEDIAPIPE SETUP kh·ªüi t·∫°o b·ªô ph√°t hi·ªán khu√¥n m·∫∑t
# =========================
mp_face = mp.solutions.face_detection # s·ª≠ d·ª•ng m√¥-ƒëun ph√°t hi·ªán khu√¥n m·∫∑t
detector = mp_face.FaceDetection(0.6) # kh·ªüi t·∫°o b·ªô ph√°t hi·ªán v·ªõi ng∆∞·ª°ng tin c·∫≠y 0.6

# =========================
# T·∫†O TH∆Ø M·ª§C C·∫¢M X√öC N·∫æU CH∆ØA T·ªíN T·∫†I
# =========================
for emo in EMOTIONS: # duy·ªát qua t·ª´ng c·∫£m x√∫c
    folder = os.path.join(DATA_DIR, emo) # ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c c·∫£m x√∫c
    if not os.path.exists(folder): # n·∫øu th∆∞ m·ª•c ch∆∞a t·ªìn t·∫°i
        os.makedirs(folder) # t·∫°o th∆∞ m·ª•c


# =========================
# THU TH·∫¨P THEO PH√çM T
# =========================
def collect(emotion): # h√†m thu th·∫≠p d·ªØ li·ªáu cho c·∫£m x√∫c ƒë∆∞·ª£c ch·ªçn

    save_folder = os.path.join(DATA_DIR, emotion) # th∆∞ m·ª•c l∆∞u ·∫£nh
    print(f"\nüì∏ CH·∫æ ƒê·ªò CH·ª§P TH·ª¶ C√îNG ‚Äì c·∫£m x√∫c: {emotion}") 
    print("‚û° Nh·∫•n ph√≠m T ƒë·ªÉ ch·ª•p ·∫£nh")
    print("‚û° Nh·∫•n ph√≠m Q ƒë·ªÉ tho√°t\n")

    cap = cv2.VideoCapture(CAMERA_INDEX, cv2.CAP_DSHOW) # m·ªü camera
    if not cap.isOpened(): # ki·ªÉm tra camera c√≥ m·ªü ƒë∆∞·ª£c kh√¥ng
        print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c camera")
        return
    
    count = len(os.listdir(save_folder))  # ti·∫øp t·ª•c t·ª´ s·ªë ·∫£nh hi·ªán c√≥ tr√°nh ghi ƒë√®

    while True: # ƒë·ªçc t·ª´ng frame(khung h√¨nh) t·ª´ camera
        ret, frame = cap.read()# ƒë·ªçc frame
         # ki·ªÉm tra ƒë·ªçc frame c√≥ th√†nh c√¥ng kh√¥ng
        if not ret:
            print("‚ö† Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame")
            continue

        frame = cv2.flip(frame, 1) # l·∫≠t ngang khung h√¨nh ƒë·ªÉ gi·ªëng g∆∞∆°ng
        h, w, _ = frame.shape # l·∫•y k√≠ch th∆∞·ªõc khung h√¨nh

        # Detect face
        results = detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))# ph√°t hi·ªán khu√¥n m·∫∑t

        if results.detections: # n·∫øu ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t
            det = results.detections[0].location_data.relative_bounding_box # l·∫•y h·ªôp gi·ªõi h·∫°n khu√¥n m·∫∑t ƒë·∫ßu ti√™n
            x1 = int(det.xmin * w) # t√≠nh t·ªça ƒë·ªô x1
            y1 = int(det.ymin * h) # t√≠nh t·ªça ƒë·ªô y1
            x2 = int((det.xmin + det.width) * w) # t√≠nh t·ªça ƒë·ªô x2
            y2 = int((det.ymin + det.height) * h) # t√≠nh t·ªça ƒë·ªô y2

            # V·∫Ω khung m·∫∑t
            cv2.rectangle(frame, (x1,y1), (x2,y2), (255,0,255), 2) # v·∫Ω h√¨nh ch·ªØ nh·∫≠t quanh m·∫∑t
            cv2.putText(frame, "Nhan phim T de chup", (10,40), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

        cv2.imshow("Manual Capture", frame) # hi·ªÉn th·ªã khung h√¨nh

        key = cv2.waitKey(1) & 0xFF # ƒë·ª£i ph√≠m nh·∫•n

        # Tho√°t
        if key == ord('q'): 
            break

        # Ch·ª•p ·∫£nh n·∫øu nh·∫•n T
        if key == ord('t'):
            if results.detections: # n·∫øu ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t
                face = frame[y1:y2, x1:x2] # c·∫Øt khu√¥n m·∫∑t t·ª´ khung h√¨nh

                if face.size > 0: # ki·ªÉm tra khu√¥n m·∫∑t c√≥ k√≠ch th∆∞·ªõc h·ª£p l·ªá
                    face_gray = cv2.cvtColor(
                        cv2.resize(face, (48,48)), # thay ƒë·ªïi k√≠ch th∆∞·ªõc v·ªÅ 48x48 v√¨ ph·ªï bi·∫øn/ th∆∞·ªùng d√πng cho nh·∫≠n di·ªán c·∫£m x√∫c
                        cv2.COLOR_BGR2GRAY  # chuy·ªÉn sang ·∫£nh x√°m
                    )

                    filepath = os.path.join(save_folder, f"{count}.jpg")# ƒë∆∞·ªùng d·∫´n l∆∞u ·∫£nh
                    cv2.imwrite(filepath, face_gray) # l∆∞u ·∫£nh
                    print(f"‚úî ƒê√É CH·ª§P: {filepath}") # in th√¥ng b√°o ƒë√£ ch·ª•p

                    count += 1 # tƒÉng b·ªô ƒë·∫øm ·∫£nh
                    time.sleep(0.3)  # tr√°nh ch·ª•p tr√πng khi gi·ªØ T

            else:
                print("‚ö† Kh√¥ng th·∫•y m·∫∑t ‚Äì kh√¥ng th·ªÉ ch·ª•p")

    cap.release() # gi·∫£i ph√≥ng camera
    cv2.destroyAllWindows() # ƒë√≥ng t·∫•t c·∫£ c·ª≠a s·ªï hi·ªÉn th·ªã
    print("\nüéâ ƒê√É THO√ÅT CH·∫æ ƒê·ªò CH·ª§P\n") 


# =========================
# MENU CH·ªåN C·∫¢M X√öC
# =========================
print("Ch·ªçn c·∫£m x√∫c mu·ªën ch·ª•p:") # in ra menu ch·ªçn c·∫£m x√∫c
for i, emo in enumerate(EMOTIONS): # duy·ªát qua t·ª´ng c·∫£m x√∫c v·ªõi ch·ªâ s·ªë
    print(f"{i}. {emo}") # in ch·ªâ s·ªë v√† t√™n c·∫£m x√∫c

choice = int(input("\nNh·∫≠p s·ªë: ")) # nh·∫≠p l·ª±a ch·ªçn t·ª´ ng∆∞·ªùi d√πng
collect(EMOTIONS[choice]) # g·ªçi h√†m thu th·∫≠p d·ªØ li·ªáu cho c·∫£m x√∫c ƒë∆∞·ª£c ch·ªçn
